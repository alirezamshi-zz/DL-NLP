{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (EE-686)\n",
    "Editor: Alireza Mohammadshahi, Florian Mai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a simple Neural Network\n",
    "\n",
    " Build a neural network with a minimun of 2 layers in order to do classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f44a126b7f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import torch.utils.data as utils\n",
    "import time\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from torch.utils.data import Dataset\n",
    "import pdb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a PyTorch Dataset and DataLoaders\n",
    "PyTorch provides standardized interfaces for handeling datasets and data loading during neural network training. For a detailed explanation visit [the PyTorch tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class).\n",
    "\n",
    "One of the most important components is the abstract 'Dataset' class. It merely requires to implement the '\\__getitem__' function, which returns the i-th example from the dataset for a given i, and the '\\__len__' function, which returns the total number of examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClassificationDataset(Dataset):\n",
    "    \"\"\"Randomly generates a classificaton dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes = 2, n_features = 100, n_samples = 10000):\n",
    "        self.X, self.y = make_classification(n_classes = n_classes, n_features = n_features, n_samples = n_samples)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.X[index], dtype=torch.float), torch.tensor(self.y[index], dtype=torch.long)\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other important component are 'Sampler's and 'DataLoader's. The former determines the order in which the examples appear during training, e.g., the 'RandomSampler' draws examples randomly. The latter is mainly responsible for loading and batching multiple examples based on the sampling strategy.\n",
    "\n",
    "In the following 'get\\_train\\_valid\\_loader', we create two subsamplers to split 10% from the training set for use as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(dataset,\n",
    "                           batch_size=64,\n",
    "                           random_seed = 1,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over a dataest.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    # split into train and validation sets\n",
    "    num_train = len(dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return (train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network architecture\n",
    "In theory, it is possible to simply chain the basic operations that we have got to know last week to build up the entire neural network. However, it is more convenient to comply with the PyTorch framework, where every neural network (component) is implemented as a subclass of 'torch.nn.Module'. This makes it possible to reuse them again as components in other modules. \n",
    "\n",
    "In the example below, 'nn.Linear' and 'nn.ReLU' are such components that are used in our 'SimpleNet' architecture by instantiating them in the constructor and using them in the 'forward' function. Intuitively, the 'forward' function implements the forward pass through the network, and makes use of the 'forward' implementations of it's components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create a simple feedforward neural network with a single hidden layer. \n",
    "    Takes as input a tensor of size [batch_size, n_feature] and returns a tensor of size [batch_size, n_output].\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    - n_feature: Size of the input data.\n",
    "    - n_hidden: Number of hidden units.\n",
    "    - n_output: Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature, n_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fcout = nn.Linear(n_hidden,n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fcout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure\n",
    "Because PyTorch provides convenient functionality for doing the forward and backward pass, the core of the training loop consists of \n",
    "* a forward pass to get the predictions\n",
    "* computing the error/loss\n",
    "* a backward pass, i.e., computing the gradients via back-propagation\n",
    "* applying an optimizer step.\n",
    "\n",
    "In PyTorch, each of these steps is a one-liner, as you can see in the example below. However, before doing the backward() step, it is important to call optimizer.zero_grad(), because otherwise the gradients from previous iterations will be retained, which is undesirable in the usual case.\n",
    "\n",
    "The remainder of the code is for adjusting the learning rate (if needed) and tracking the validation set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(learning_rate, optimizer, loss_func, net, trainloader, valloader, \n",
    "          compute_correct_outputs, \n",
    "          epochs = 30,\n",
    "          update_lr = 4,\n",
    "          decay_rate = 0.8,\n",
    "          print_every = 20):\n",
    "    \n",
    "    def adjust_learning_rate(lr,update_lr, optimizer, epoch):\n",
    "        lr = lr * (decay_rate ** (epoch // update_lr))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    best_val = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        adjust_learning_rate(learning_rate,update_lr,optimizer,e)\n",
    "        start = time.time()\n",
    "        for data, labels in iter(trainloader):\n",
    "            steps += 1\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(data)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                    stop = time.time() \n",
    "                    # Test accuracy\n",
    "                    net.eval()\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    with torch.no_grad():\n",
    "                        for data in valloader:\n",
    "                            images, labels = data\n",
    "                            images = images.to(device)\n",
    "                            labels = labels.to(device)\n",
    "                            outputs = net(images)\n",
    "                            total += labels.size(0)\n",
    "                            correct += compute_correct_outputs(outputs, labels)\n",
    "                            \n",
    "                        accuracy = 100.0 * correct / total\n",
    "                        print('Accuracy of the network on the %d val data: \\\n",
    "                        %f %%' % (total,accuracy))\n",
    "                        if (accuracy > best_val):\n",
    "                            best_val = accuracy\n",
    "                            torch.save(net.state_dict(),'model.ckpt')\n",
    "\n",
    "                    start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correct_classification(outputs, labels):\n",
    "    _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the optimizer\n",
    "Finally, it remains to choose an appropriate loss function and optimizer.\n",
    "The 'CrossEntropyLoss' module expects the class labels and the predicted logits as input, applies softmax to it, and returns the negative loglikelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fcout): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the dataset and loaders\n",
    "dataset = RandomClassificationDataset()\n",
    "trainloader, valloader = get_train_valid_loader(dataset)\n",
    "\n",
    "# instantiate the neural net\n",
    "net = SimpleNet(n_feature=100, n_hidden=10, n_output=2)     # define the network\n",
    "print(net)  # net architecture\n",
    "\n",
    "# define loss and optimizer\n",
    "learning_rate = 1.5e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  # Choose the optimizer you want and tune its hyperparameter\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Accuracy of the network on the 1000 val data:                         50.300000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmai/anaconda3/envs/dlnlp/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 val data:                         50.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         51.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         52.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         52.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         53.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         53.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         54.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         55.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         57.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         58.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         59.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         61.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         62.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         64.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         65.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         66.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         67.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         68.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         69.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         71.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         72.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         73.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         74.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         74.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         75.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         76.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         77.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         78.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         78.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         79.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         80.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         80.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         80.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         81.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         81.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         82.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         82.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         83.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         83.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         83.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         83.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         84.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         84.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         85.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         85.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         86.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         86.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         87.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         87.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         87.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         87.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         88.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         88.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         88.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         88.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         88.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         89.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         90.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         91.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.300000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.100000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.200000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.300000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.400000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.500000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.600000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.700000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.800000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         92.900000 %\n",
      "Accuracy of the network on the 1000 val data:                         93.000000 %\n"
     ]
    }
   ],
   "source": [
    "train(learning_rate, optimizer, loss_func, net, trainloader, valloader, compute_correct_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model should be saved to be tested on the test dataset or to be used in a real-life application. To save a model in pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model.ckpt\")\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Your task is to implement a feed forward neural network to classify an image dataset. The dataset contains 10 classes of images, and you should write a simple neural network to classify it with a reasonable accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions:\n",
    "\n",
    "We give you the helper function to load and preprocess the dataset, so you should just write your network and the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170418176/170498071 [02:45<00:00, 1118278.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [03:00, 1118278.62it/s]                               "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "def get_train_valid_loader(data_dir='../data',\n",
    "                           batch_size=64,\n",
    "                           augment=False,\n",
    "                           random_seed = 1,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=9, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory,\n",
    "        )\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy().transpose([0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "trainloader, valloader = get_train_valid_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
